Adversarial attacks are being studied because they can expose vulnerabilities in machine learning models, which is important for improving the robustness and security of these systems in various real-world applications. Adversarial attacks are the deliberate manipulation of input data to trick a machine learning model into making incorrect predictions. Adversarial attacks are especially bad in applications such as image/speech recognition and autonomous vehicles, where incorrect predictions can have potentially dangerous consequences. Studying these attacks helps to understand the weaknesses of machine learning models and to develop better defense mechanisms against these types of attacks.