@misc{CPP_GUIDE,
    author = {NVIDIA},
    title = {CUDA C++ Programming Guide Release 12.4},
    year = {2024},
    url = {https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html}
}

@techreport{FAMOUS_CHIPS,
    author = {Dr. John Peddie},
    title = {Famous Graphics Chips: Nvidia’s GeForce 256},
    institution = {IEEE Computer Society},
    year = {2021},
    url = {https://www.computer.org/publications/tech-news/chasing-pixels/nvidias-geforce-256}
}

@inproceedings{Parallel_Techniques,
author = {Ellis, Clarence A.},
title = {Parallel compiling techniques},
year = {1971},
isbn = {9781450374842},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800184.810520},
doi = {10.1145/800184.810520},
abstract = {Currently, the software technology is not keeping up with the hardware technology. New software must be planned to take advantage of new hardware innovations. This paper describes one such effort. Techniques are described for carrying out the compilation process on a global highly-parallel computer. The problem of data structures and organization within the parallel computer is considered, and two organizations, called the horizontal and the vertical data organizations, are investigated.},
booktitle = {Proceedings of the 1971 26th Annual Conference},
pages = {508–519},
numpages = {12},
keywords = {Procedure oriented languages, Parallel programming languages, Parallel programming, Parallel computers, Parallel compiling, Parallel compilers, Content addressing, Compilers, Associative processing, Associative computer languages},
series = {ACM '71}
}

@article{LPC,
author = {Schwartz, J.},
title = {Large Parallel Computers},
year = {1966},
issue_date = {Jan. 1966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {1},
issn = {0004-5411},
url = {https://doi.org/10.1145/321312.321315},
doi = {10.1145/321312.321315},
abstract = {Various classes of machines incorporating parallelism are considered. A general class of large-scale multiprocessors is outlined, and some problems of hardware and software implementation for computers of this class are discussed.},
journal = {J. ACM},
month = {jan},
pages = {25–32},
numpages = {8}
}


@misc{IBM_POWER4,
    author = {IBM},
    title = {The IBM Power4},
    year = {Accessed April 20, 2024},
    url = {https://www.ibm.com/history/power}
}

@misc{AMD_ATHLON64X2,
    author = {AMD},
    title = {AMD Athlon™ 64 X2 Dual-Core Processor Product Data Sheet},
    year = {2007},
    url = {https://www.amd.com/content/dam/amd/en/documents/archived-tech-docs/datasheets/33425.pdf}
}

@misc{INTEL_PENTIUMD,
    author = {Intel},
    title = {Intel® Pentium® D Processor 820 Specifications},
    year = {Accessed April 20, 2024},
    url = {https://www.intel.com/content/www/us/en/products/sku/27512/intel-pentium-d-processor-820-2m-cache-2-80-ghz-800-mhz-fsb/specifications.html}
}

@misc{INTEL_14900K,
    author = {Intel},
    title = {Intel® Core™ i9 processor 14900K Specifications},
    year = {Accessed April 20, 2024},
    url = {https://www.intel.com/content/www/us/en/products/sku/236773/intel-core-i9-processor-14900k-36m-cache-up-to-6-00-ghz/specifications.html}
}

@misc{INTEL_CORE3,
    author = {Intel},
    title = {Intel® Core™ 3 processor 100UL Specifications},
    year = {Accessed April 20, 20224},
    url = {https://www.intel.com/content/www/us/en/products/sku/239173/intel-core-3-processor-100ul-10m-cache-up-to-4-50-ghz/specifications.html}
}

@book{CG_TUTORIAL,
    author = "Fernando, Randima and Kilgard, Mark",
    title = {The Cg Tutorial: The Definitive Guide to Programmable Real-Time Graphics},
    publisher = {Addison-Wesley},
    year = {2003},
    url = {https://developer.download.nvidia.com/CgTutorial/cg_tutorial_chapter01.html}
}

@misc{DIRECTX7,
    author = {Microsoft},
    title = {Microsoft Ships Final Release of DirectX 7.0},
    year = {1999},
    url = {https://news.microsoft.com/1999/09/22/microsoft-ships-final-release-of-directx-7-0/}
}

@misc{OPENGL1.0,
    author = "Segal, Mark and Akeley, Kurt",
    title = {The OpenGL Graphics System: A specification (Version 1.0)},
    year = {1994},
    url = {https://registry.khronos.org/OpenGL/specs/gl/glspec10.pdf}
}

@misc{STAR_WARS,
    author = {Platt College},
    title = {Star Wars | Visual Effects through the years},
    url = {https://platt.edu/blog/a-breakdown-of-the-visual-effects-used-in-the-star-wars-franchise}
}

@misc{MOVIES_CGI,
    author = {Trey, Nissley},
    title = {9 Groundbreaking Movies in the Early History of CGI},
    year = {2022},
    url = {https://movieweb.com/first-movies-with-cgi/}
}
@misc{COMPUTE_CAPABILITY,
    author = {NVIDIA},
    title = {Your GPU Compute Capability},
    year = {Accessed April 22, 2024},
    url = {https://developer.nvidia.com/cuda-gpus}
}

@misc{H100_ARCHITECTURE,
    author = {NVIDIA},
    title = {NVIDIA H100 Tensor Core GPU Architecture v1.04},
    year = {2023},
    url = {https://resources.nvidia.com/en-us-tensor-core/gtc22-whitepaper-hopper}
}

@misc{NSIGHT_USER_GUIDE,
    author = {NVIDIA},
    title = {Nsight User Guide v2024.2},
    year = {2024},
    url = {https://docs.nvidia.com/nsight-systems/UserGuide/index.html}
}

@inproceedings{FLOOD_SIMULATION,
author = {Ko, Chin-Pin and Chittem, Praveen Kumar and Hsu, Chiang-An and Alkhaleefah, Mohammad and Huang, Min-Jui and Chang, Yang-Lang},
title = {CUDA-enabled Programming for Accelerating Flood Simulation},
year = {2021},
isbn = {9781450389419},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474906.3474916},
doi = {10.1145/3474906.3474916},
abstract = {Floods are the most frequent disasters, causing widespread damage resulting in loss of lives and properties. In this paper, we present Sinotech Engineering Consultants Hydrodynamic (SEC-HY21) simulation modeling to predicted floods and estimate their damage efficiently. However, SEC-HY21 still suffers from the slow simulation rate due to its data dependency structure which does not make the numerical model of SEC-HY21 parallelizable. In this research, a near real-time flood simulation has been reached by Compute Uniﬁed Device Architecture (CUDA) parallel implementation on NVIDIA Graphics Processing Unit (GPU) to accelerate the performance of the slowest module in the SEC-HY21 package, namely iFlux. The experimental results have shown that the CUDA-based parallel implementation has made the SEC-HY21 simulation modeling 14x faster than before.},
booktitle = {Proceedings of the 5th International Conference on Graphics and Signal Processing},
pages = {72–75},
numpages = {4},
keywords = {CUDA, Flood simulation, SEC-HY21, high-performance computing, parallel programming},
location = {Nagoya, Japan},
series = {ICGSP '21}
}

@inproceedings{MOLECULAR_DOCKING,
author = {Roh, Youngtae and Lee, Jun and Park, Sungjun and Kim, Jee-In},
title = {A molecular docking system using CUDA},
year = {2009},
isbn = {9781605586625},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1644993.1644999},
doi = {10.1145/1644993.1644999},
abstract = {A Molecular Docking System enables biologists to check whether two molecular models can be combined at a specific position and remain in their stable states by simulation. It can be used in developing new materials and designing new drugs. Since the docking simulation consists of several complicated computations at the level of atoms, it requires high computing capabilities such as super computers and parallel computing systems. We propose a molecular docking system using parallel GPUs in this paper. In our proposed method, a GPU can process an equation as a single logical work unit. The computations can be executed through parallel GPUs in real-time. The proposed system was evaluated in its performance by comparing with conventional CPU-based systems. A series of experiments for measuring performance of the system showed that our system is 33 to 287 times faster than the CPU-based systems.},
booktitle = {Proceedings of the 2009 International Conference on Hybrid Information Technology},
pages = {28–33},
numpages = {6},
keywords = {molecular docking simulation, GPGPU, CUDA},
location = {Daejeon, Korea},
series = {ICHIT '09}
}

@article{AUTODOC_MOLECULARDOCKING,
title = {Benchmarking the performance of irregular computations in AutoDock-GPU molecular docking},
journal = {Parallel Computing},
volume = {109},
pages = {102861},
year = {2022},
issn = {0167-8191},
doi = {https://doi.org/10.1016/j.parco.2021.102861},
url = {https://www.sciencedirect.com/science/article/pii/S0167819121001046},
author = {Leonardo Solis-Vasquez and Andreas F. Tillack and Diogo Santos-Martins and Andreas Koch and Scott LeGrand and Stefano Forli},
keywords = {Variable execution performance, Molecular docking, Early termination, OpenCL, CUDA, },
abstract = {Irregular applications can be found in different scientific fields. In computer-aided drug design, molecular docking simulations play an important role in finding promising drug candidates. AutoDock is a software application widely used for predicting molecular interactions at close distances. It is characterized by irregular computations and long execution runtimes. In recent years, a hardware-accelerated version of AutoDock, called AutoDock-GPU, has been under active development. This work benchmarks the recent code and algorithmic enhancements incorporated into AutoDock-GPU. Particularly, we analyze the impact on execution runtime of techniques based on early termination. These enable AutoDock-GPU to explore the molecular space as necessary, while safely avoiding redundant computations. Our results indicate that it is possible to achieve average runtime reductions of 50\% by using these techniques. Furthermore, a comprehensive literature review is also provided, where our work is compared to relevant approaches leveraging hardware acceleration for molecular docking.}
}











@article{ACCELERATING_DNN,
author={D T V Dharmajee,Rao and Ramana,K. V.},
year={2019},
month={05},
title={Accelerating Training of Deep Neural Networks on GPU using CUDA},
journal={International Journal of Intelligent Systems and Applications},
volume={10},
number={5},
pages={18},
note={Copyright - 2019. Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the associated terms available at http://www.mecs-press.org/ijcnis/terms.html; Last updated - 2024-03-25},
abstract={The development of fast and efficient training algorithms for Deep Neural Networks has been a subject of interest over the past few years because the biggest drawback of Deep Neural Networks is enormous cost in computation and large time is consumed to train the parameters of Deep Neural Networks. This aspect motivated several researchers to focus on recent advancements of hardware architectures and parallel programming models and paradigms for accelerating the training of Deep Neural Networks. We revisited the concepts and mechanisms of typical Deep Neural Network training algorithms such as Backpropagation Algorithm and Boltzmann Machine Algorithm and observed that the matrix multiplication constitutes major portion of the work-load for the Deep Neural Network training process because it is carried out for a huge number of times during the training of Deep Neural Networks. With the advent of many-core GPU technologies, a matrix multiplication can be done very efficiently in parallel and this helps a lot training a Deep Neural Network not consuming time as it used to be a few years ago. CUDA is one of the high performance parallel programming models to exploit the capabilities of modern many-core GPU systems. In this paper, we propose to modify Backpropagation Algorithm and Boltzmann Machine Algorithm with CUDA parallel matrix multiplication and test on many-core GPU system. Finally we discover that the planned strategies achieve very quick training of Deep Neural Networks than classic strategies.},
keywords={Computers--Computer Systems; Deep Neural Networks; Parallel computing; Cuda; Deep learning; Graphics processing unit; Matrix multiplication; Many-core GPU systems; Multiplication; Algorithms; Parallel programming; Back propagation; Neural networks; Artificial neural networks},
isbn={2074904X},
language={English},
url={http://ezp.lib.cwu.edu/login?url=https://www.proquest.com/scholarly-journals/accelerating-training-deep-neural-networks-on-gpu/docview/2268345992/se-2},
}


@misc{MONAI_TOOLKIT,
    author = {NVIDIA},
    title = {MONAI Toolkit},
    year = {2024},
    url = {https://catalog.ngc.nvidia.com/orgs/nvidia/teams/clara/containers/monai-toolkit}
}

@misc{NVIDIA_FLARE,
    author = {NVIDIA},
    title = {NVIDIA FLARE Documentation},
    year = {Accessed April 22, 2024},
    url = {https://nvflare.readthedocs.io/en/main/index.html}
}

@article{CUDA_FOR_MEDICAL_IMAGING,
title = {Survey of using GPU CUDA programming model in medical image analysis},
journal = {Informatics in Medicine Unlocked},
volume = {9},
pages = {133-144},
year = {2017},
issn = {2352-9148},
doi = {https://doi.org/10.1016/j.imu.2017.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S235291481730045X},
author = {T. Kalaiselvi and P. Sriramakrishnan and K. Somasundaram},
keywords = {GPU CUDA, Medical imaging, Parallel computing, Denoising, Segmentation, Visualization},
abstract = {With the technology development of medical industry, processing data is expanding rapidly and computation time also increases due to many factors like 3D, 4D treatment planning, the increasing sophistication of MRI pulse sequences and the growing complexity of algorithms. Graphics processing unit (GPU) addresses these problems and gives the solutions for using their features such as, high computation throughput, high memory bandwidth, support for floating-point arithmetic and low cost. Compute unified device architecture (CUDA) is a popular GPU programming model introduced by NVIDIA for parallel computing. This review paper briefly discusses the need of GPU CUDA computing in the medical image analysis. The GPU performances of existing algorithms are analyzed and the computational gain is discussed. A few open issues, hardware configurations and optimization principles of existing methods are discussed. This survey concludes the few optimization techniques with the medical imaging algorithms on GPU. Finally, limitation and future scope of GPU programming are discussed.}
}

@article{IMAGE_DENOISING,
    author = {A. Eklund and M. Anderson and H. Knutsson},
    title = {True 4D Image Denoising on the GPU},
    journal = {International Journal of Biomedical Imaging},
    year = {2011},
    doi = {https://doi.org/10.1155/2011/952819},
    url = {https://www.hindawi.com/journals/ijbi/2011/952819/}
}

@INPROCEEDINGS{EM_ICP_ON_GPU,
  author={Tamaki, Toru and Abe, Miho and Raytchev, Bisser and Kaneda, Kazufumi},
  booktitle={2010 First International Conference on Networking and Computing}, 
  title={Softassign and EM-ICP on GPU}, 
  year={2010},
  volume={},
  number={},
  pages={179-183},
  keywords={Iterative closest point algorithm;Three dimensional displays;Graphics processing unit;Kernel;Quaternions;Estimation;Software algorithms;Softassign;EM-ICP;ICP;3D points;point cloud;registration;CUDA;GPU},
  doi={10.1109/IC-NC.2010.60}
}

@article{CPU_AND_GPU_ACCELERATING_IMAGE_APPLICATIONS,
  title={Performance analysis of morphological operations in CPU and GPU for accelerating digital image applications},
  author={Kalaiselvi, T and Sriramakrishnan, P and Somasundaram, K},
  journal={International Journal of Computationa Science and Information Technology (IJCSITY)},
  pages={15--27},
  year={2016}
}

@book{korte2011combinatorial,
  title={Combinatorial optimization},
  author={Korte, Bernhard H and Vygen, Jens and Korte, B and Vygen, J},
  volume={1},
  year={2011},
  publisher={Springer}
}

@book{papadimitriou1998combinatorial,
  title={Combinatorial optimization: algorithms and complexity},
  author={Papadimitriou, Christos H and Steiglitz, Kenneth},
  year={1998},
  publisher={Courier Corporation}
}

@article{blum2003metaheuristic,
author = {Blum, Christian and Roli, Andrea},
title = {Metaheuristics in combinatorial optimization: Overview and conceptual comparison},
year = {2003},
issue_date = {September 2003},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {35},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/937503.937505},
doi = {10.1145/937503.937505},
abstract = {The field of metaheuristics for the application to combinatorial optimization problems is a rapidly growing field of research. This is due to the importance of combinatorial optimization problems for the scientific as well as the industrial world. We give a survey of the nowadays most important metaheuristics from a conceptual point of view. We outline the different components and concepts that are used in the different metaheuristics in order to analyze their similarities and differences. Two very important concepts in metaheuristics are intensification and diversification. These are the two forces that largely determine the behavior of a metaheuristic. They are in some way contrary but also complementary to each other. We introduce a framework, that we call the I&D frame, in order to put different intensification and diversification components into relation with each other. Outlining the advantages and disadvantages of different metaheuristic approaches we conclude by pointing out the importance of hybridization of metaheuristics as well as the integration of metaheuristics and other methods for optimization.},
journal = {ACM Comput. Surv.},
month = {sep},
pages = {268–308},
numpages = {41},
keywords = {Metaheuristics, combinatorial optimization, diversification., intensification}
}

@inproceedings{chen2011cuda,
  title={CUDA-based genetic algorithm on traveling salesman problem},
  author={Chen, Su and Davis, Spencer and Jiang, Hai and Novobilski, Andy},
  booktitle={Computer and Information Science 2011},
  pages={241--252},
  year={2011},
  organization={Springer}
}

@article{hlaing2011solving,
  title={Solving traveling salesman problem by using improved ant colony optimization algorithm},
  author={Hlaing, Zar Chi Su Su and Khine, May Aye},
  journal={International Journal of Information and Education Technology},
  volume={1},
  number={5},
  pages={404},
  year={2011},
  publisher={IACSIT Press}
}

@article{wang2021ant,
  title={Ant colony optimization for traveling salesman problem based on parameters optimization},
  author={Wang, Yong and Han, Zunpu},
  journal={Applied Soft Computing},
  volume={107},
  pages={107439},
  year={2021},
  publisher={Elsevier}
}

@article{skinderowicz2022improving,
  title={Improving Ant Colony Optimization efficiency for solving large TSP instances},
  author={Skinderowicz, Rafa{\l}},
  journal={Applied Soft Computing},
  volume={120},
  pages={108653},
  year={2022},
  publisher={Elsevier}
}

@article{CACCHIANI2022105693,
title = {Knapsack problems — An overview of recent advances. Part II: Multiple, multidimensional, and quadratic knapsack problems},
journal = {Computers \& Operations Research},
volume = {143},
pages = {105693},
year = {2022},
issn = {0305-0548},
doi = {https://doi.org/10.1016/j.cor.2021.105693},
url = {https://www.sciencedirect.com/science/article/pii/S0305054821003889},
author = {Valentina Cacchiani and Manuel Iori and Alberto Locatelli and Silvano Martello},
keywords = {Survey, Combinatorial optimization, Multiple and multidimensional knapsack problems, Quadratic knapsack problems},
abstract = {After the seminal books by Martello and Toth (1990) and Kellerer, Pferschy, and Pisinger (2004), knapsack problems became a classical and rich research area in combinatorial optimization. The purpose of this survey, structured in two parts, is to cover the developments appeared in this field after the publication of the latter volume. Part I treats the classical single knapsack problems and their variants. The present Part II covers multiple, multidimensional, and quadratic knapsack problems, as well as other relevant variants, such as, e.g., multiobjective and online versions.}
}

@book{jensen2011graph,
  title={Graph coloring problems},
  author={Jensen, Tommy R and Toft, Bjarne},
  year={2011},
  publisher={John Wiley \& Sons}
}

@article{liu2023heuristics,
  title={Heuristics for Vehicle Routing Problem: A Survey and Recent Advances},
  author={Liu, Fei and Lu, Chengyu and Gui, Lin and Zhang, Qingfu and Tong, Xialiang and Yuan, Mingxuan},
  journal={arXiv preprint arXiv:2303.04147},
  year={2023}
}

@article{yang2008ant,
  title={An ant colony optimization method for generalized TSP problem},
  author={Yang, Jinhui and Shi, Xiaohu and Marchese, Maurizio and Liang, Yanchun},
  journal={Progress in Natural Science},
  volume={18},
  number={11},
  pages={1417--1422},
  year={2008},
  publisher={Elsevier}
}

@article{dorigo1996ant,
  title={Ant system: optimization by a colony of cooperating agents},
  author={Dorigo, Marco and Maniezzo, Vittorio and Colorni, Alberto},
  journal={IEEE transactions on systems, man, and cybernetics, part b (cybernetics)},
  volume={26},
  number={1},
  pages={29--41},
  year={1996},
  publisher={Ieee}
}

@article{maxminant,
author = {Stützle, Thomas and Hoos, Holger},
year = {2000},
month = {06},
pages = {},
title = {The Max-Min ANT System and Local Search for Combinatorial Optimization Problems},
volume = {16},
isbn = {978-0-7923-8369-7},
journal = {Future Generation Computer Systems},
doi = {10.1007/978-1-4615-5775-3_22}
}

@article{LI2015994,
title = {Parallel ant colony optimization for the determination of a point heat source position in a 2-D domain},
journal = {Applied Thermal Engineering},
volume = {91},
pages = {994-1002},
year = {2015},
issn = {1359-4311},
doi = {https://doi.org/10.1016/j.applthermaleng.2015.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S1359431115008959},
author = {B.H. Li and M. Lu and Y.G. Shan and H. Zhang},
keywords = {Inverse heat source problems, Ant colony optimization (ACO), Parallel strategies},
abstract = {The Ant Colony Optimization (ACO) and its parallel implementations are applied to determine the unknown position of a point heat source in a two-dimensional steady-state heat conduction problem. The heuristic value, the determination of path and the objective function are all studied based on the inverse heat source problem. Some of the standard steps of the ACO are also modified according to the features of the heat conduction problem. In order to accelerate the speed of solving the inverse problem, two kinds of parallel ACO strategies, the fine-grained master-slave strategy and the coarse-grained strategy combined with the above modification are studied in this paper. The results show that the fine-grained strategy has a higher speedup than the coarse-grained strategy whiles the coarse-grained strategy has a higher accuracy rate. This means that the coarse-grained strategy is more proper during the parallel implementation for solving the inverse heat source problem and the parallel implementation of the ACO can improve the computational efficiency.}
}

@article{STARZEC2020125,
title = {Desynchronization in distributed Ant Colony Optimization in HPC environment},
journal = {Future Generation Computer Systems},
volume = {109},
pages = {125-133},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2020.03.045},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19327402},
author = {Mateusz Starzec and Grażyna Starzec and Aleksander Byrski and Wojciech Turek and Kamil Piętak},
abstract = {Metaheuristics have significant computing requirements, in particular Ant Colony Optimization (ACO) processes a population of individuals (agents/ants) roaming in a graph, leaving the pheromone trails and getting inspired by its amount perceived on the edges. If the considered problem instance is large or the time is crucial, one can try to leverage parallel, hybrid or distributed infrastructure, but the algorithm itself must be properly prepared to deal with new possibilities. We have already presented a method for efficient implementation of distributed ACO, in this paper we follow up with introducing planned desynchronization in the pheromone matrix updates in order to further increase the scalability of the proposed system. The proposed modifications allowed the algorithm to scale up to 400 computations nodes without a significant impact on results quality. Efficacy of the algorithm outperforms the standard Max–Min Ant System by 10\%.}
}


@INPROCEEDINGS{6337497,
  author={C'ceres, E.N. and Fingler, H. and Mongelli, H. and Song, S.W.},
  booktitle={2012 41st International Conference on Parallel Processing Workshops}, 
  title={Ant Colony System Based Solutions to the Quadratic Assignment Problem on GPGPU}, 
  year={2012},
  volume={},
  number={},
  pages={314-322},
  keywords={Production facilities;Graphics processing unit;Hospitals;Approximation methods;Materials;Instruction sets;Approximation algorithms;QAP;Ant Colony;GPGPU},
  doi={10.1109/ICPPW.2012.47}}


@inproceedings{chen2011cuda,
  title={CUDA-based genetic algorithm on traveling salesman problem},
  author={Chen, Su and Davis, Spencer and Jiang, Hai and Novobilski, Andy},
  booktitle={Computer and Information Science 2011},
  pages={241--252},
  year={2011},
  organization={Springer}
}

@Inbook{clt2008,
title="Central Limit Theorem",
bookTitle="The Concise Encyclopedia of Statistics",
year="2008",
publisher="Springer New York",
address="New York, NY",
pages="66--68",
isbn="978-0-387-32833-1",
doi="10.1007/978-0-387-32833-1_50",
url="https://doi.org/10.1007/978-0-387-32833-1_50"
}

@misc{Chitty17,
author={Chitty,Darren M.},
year={2017},
title={Applying ACO To Large Scale TSP Instances},
journal={arXiv.org},
note={Copyright - © 2017. This work is published under http://arxiv.org/licenses/nonexclusive-distrib/1.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License; Last updated - 2019-04-13},
abstract={Ant Colony Optimisation (ACO) is a well known metaheuristic that has proven successful at solving Travelling Salesman Problems (TSP). However, ACO suffers from two issues; the first is that the technique has significant memory requirements for storing pheromone levels on edges between cities and second, the iterative probabilistic nature of choosing which city to visit next at every step is computationally expensive. This restricts ACO from solving larger TSP instances. This paper will present a methodology for deploying ACO on larger TSP instances by removing the high memory requirements, exploiting parallel CPU hardware and introducing a significant efficiency saving measure. The approach results in greater accuracy and speed. This enables the proposed ACO approach to tackle TSP instances of up to 200K cities within reasonable timescales using a single CPU. Speedups of as much as 1200 fold are achieved by the technique.},
keywords={Business And Economics--Banking And Finance; Traveling salesman problem; Ant colony optimization; Iterative methods; Heuristic methods},
language={English},
url={http://ezp.lib.cwu.edu/login?url=https://www.proquest.com/working-papers/applying-aco-large-scale-tsp-instances/docview/2076629970/se-2},
}

@article{White03,
    author = {Tony White and Simon Kaegi and Terri Oda},
    title = {Revisiting Elitism in Ant Colony Optimization},
    journal = {Genetic and Evolutionary Computation-GECCO 2003},
    pages = {122-133},
    year = {2003}
}

@article{borisenko2019,
author = {Borisenko, Andrey and Gorlatch, Sergei},
year = {2019},
month = {12},
pages = {},
title = {Comparing GPU-parallelized metaheuristics to branch-and-bound for batch plants optimization},
volume = {75},
journal = {The Journal of Supercomputing},
doi = {10.1007/s11227-018-2472-9}
}

@article{WORLD_RECORD_OPTIMIZATION,
    author = {Caulfield, Brian},
    title = {Signed, Sealed, Delivered: NVIDIA AI Achieves World Record in Route Optimization},
    year = {2021},
    url = {https://blogs.nvidia.com/blog/cuopt-world-record-route/}
}

@misc{CUOPT_USER_GUIDE,
    author = {NVIDIA},
    title = {NVIDIA cuOpt User Guide 24.03},
    year = {2024},
    url = {https://docs.nvidia.com/cuopt/user-guide/introduction.html}
}

@article{GPU_ACCELERATION_OF_AI,
title = {GPU-based acceleration of evolutionary induction of model trees},
journal = {Applied Soft Computing},
volume = {119},
pages = {108503},
year = {2022},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2022.108503},
url = {https://www.sciencedirect.com/science/article/pii/S1568494622000497},
author = {Krzysztof Jurczuk and Marcin Czajkowski and Marek Kretowski},
keywords = {Evolutionary data mining, Decision trees, Regression, GPU parallel computing, Large-scale data},
abstract = {Evolutionary algorithms (EAs) are naturally prone to parallel processing. However, when they are applied to data mining, the fitness calculations start to dominate and the typical population-based decomposition limits the parallel efficiency. When dealing with large-scale data, the scalable solution may become a real challenge. In this article, we propose a GPU-based parallelization of evolutionary induction of model trees. Such trees are a special case of decision tree (DT) that is designed to solve regression problems. The evolutionary approach allows not only a robust prediction but also to preserve the simplicity of DTs. However, the global approach is much more computationally demanding than state-of-the-art greedy inducers, and thus hard to apply to large-scale data mining directly. A parallelized induction of model trees (with univariate tests in the internal nodes and multiple linear regression models in the leaves) requires a carefully designed decomposition strategy. Six GPU-supported procedures are designed to successively: redistribute, sort and rearrange dataset samples, next, calculate models and fitness, and finally gather the results. Experimental validation is performed on real-life and artificial datasets, using various (low- and high-end) GPU accelerators. Results show that the GPU-supported solution enables time-efficient global induction of model trees on large-scale data, which until now was reserved for greedy methods. The obtained speedup is very satisfactory (even up to hundreds of times). The solution is scalable for datasets of different sizes and dimensions.}
}

@article{COMPAS_REVIEW,
author = {Julia Dressel  and Hany Farid },
title = {The accuracy, fairness, and limits of predicting recidivism},
journal = {Science Advances},
volume = {4},
number = {1},
pages = {eaao5580},
year = {2018},
doi = {10.1126/sciadv.aao5580},
URL = {https://www.science.org/doi/abs/10.1126/sciadv.aao5580},
eprint = {https://www.science.org/doi/pdf/10.1126/sciadv.aao5580},
abstract = {Should we trust computers to make life-altering decisions in the criminal justice system? Algorithms for predicting recidivism are commonly used to assess a criminal defendant’s likelihood of committing a crime. These predictions are used in pretrial, parole, and sentencing decisions. Proponents of these systems argue that big data and advanced machine learning make these analyses more accurate and less biased than humans. We show, however, that the widely used commercial risk assessment software COMPAS is no more accurate or fair than predictions made by people with little or no criminal justice expertise. In addition, despite COMPAS’s collection of 137 features, the same accuracy can be achieved with a simple linear classifier with only two features.}}


@article{HOW_COMPANIES_LEARN_YOUR_SECRETS,
    author = {Starkman, D. and Hamilton, M. and Salmon, F.},
    title = {How Companies Learn Your Secrets},
    publisher = {Columbia University Press},
    journal = {The Best Business Writing},
    year = {2013},
    pages = {421-444}
}

@article{AI_EXPLAINABILITY,
    author = {Coeckelbergh, M},
    title = {Artificial Intelligence, Responsibility Attribution, and a Relational Justification of Explainability},
    journal = {Science and Engineering Ethics},
    year = {2020}
}

@misc{COMPARE_GEFORCE_CARDS,
    author = {NVIDIA},
    title = {Compare GeForce Graphics Cards},
    year = {accessed April 24, 2024},
    url = {https://www.nvidia.com/en-us/geforce/graphics-cards/compare/}
}

@article{GUTIN200281,
title = {Traveling salesman should not be greedy: domination analysis of greedy-type heuristics for the TSP},
journal = {Discrete Applied Mathematics},
volume = {117},
number = {1},
pages = {81-86},
year = {2002},
issn = {0166-218X},
doi = {https://doi.org/10.1016/S0166-218X(01)00195-0},
url = {https://www.sciencedirect.com/science/article/pii/S0166218X01001950},
author = {Gregory Gutin and Anders Yeo and Alexey Zverovich},
keywords = {TSP, Domination analysis, Greedy algorithm, Nearest neighbor algorithm},
abstract = {Computational experiments show that the greedy algorithm (GR) and the nearest neighbor algorithm (NN), popular choices for tour construction heuristics, work at acceptable level for the Euclidean TSP, but produce very poor results for the general Symmetric and Asymmetric TSP (STSP and ATSP). We prove that for every n⩾2 there is an instance of ATSP (STSP) on n vertices for which GR finds the worst tour. The same result holds for NN. We also analyze the repetitive NN (RNN) that starts NN from every vertex and chooses the best tour obtained. We prove that, for the ATSP, RNN always produces a tour, which is not worse than at least n/2−1 other tours, but for some instance it finds a tour, which is not worse than at most n−2 other tours, n⩾4. We also show that, for some instance of the STSP on n⩾4 vertices, RNN produces a tour not worse than at most 2n−3 tours. These results are in sharp contrast to earlier results by Gutin and Yeo, and Punnen and Kabadi, who proved that, for the ATSP, there are tour construction heuristics, including some popular ones, that always build a tour not worse than at least (n−2)! tours.}
}

@article{johnson1997traveling,
  title={The traveling salesman problem: a case study},
  author={Johnson, David S and McGeoch, Lyle A},
  journal={Local search in combinatorial optimization},
  pages={215--310},
  year={1997},
  publisher={Chichester}
}

@book{reinelt2003traveling,
  title={The traveling salesman: computational solutions for TSP applications},
  author={Reinelt, Gerhard},
  volume={840},
  year={2003},
  publisher={Springer}
}

@inproceedings{cirasella2001asymmetric,
  title={The asymmetric traveling salesman problem: Algorithms, instance generators, and tests},
  author={Cirasella, Jill and Johnson, David S and McGeoch, Lyle A and Zhang, Weixiong},
  booktitle={Workshop on Algorithm Engineering and Experimentation},
  pages={32--59},
  year={2001},
  organization={Springer}
}

@article{glover2001construction,
  title={Construction heuristics for the asymmetric TSP},
  author={Glover, Fred and Gutin, Gregory and Yeo, Anders and Zverovich, Alexey},
  journal={European Journal of Operational Research},
  volume={129},
  number={3},
  pages={555--568},
  year={2001},
  publisher={Elsevier}
}

@article{gutin2005evaluation,
  title={Evaluation of the contract or-patch heuristic Eor the asymmetric Tsp},
  author={Gutin, Gregory and Zverovitch, Alexei},
  journal={INFOR: Information Systems and Operational Research},
  volume={43},
  number={1},
  pages={23--31},
  year={2005},
  publisher={Taylor \& Francis}
}

@article{johnson1997traveling,
  title={The traveling salesman problem: a case study},
  author={Johnson, David S and McGeoch, Lyle A},
  journal={Local search in combinatorial optimization},
  pages={215--310},
  year={1997},
  publisher={Chichester}
}

@article{kirkpatrick1983optimization,
  title={Optimization by simulated annealing},
  author={Kirkpatrick, Scott and Gelatt Jr, C Daniel and Vecchi, Mario P},
  journal={science},
  volume={220},
  number={4598},
  pages={671--680},
  year={1983},
  publisher={American association for the advancement of science}
}

@misc{Howell_2023, title={How to solve travelling salesman problem with simulated annealing}, url={https://towardsdatascience.com/how-to-solve-travelling-salesman-problem-with-simulated-annealing-c248447a8bcd}, journal={Medium}, publisher={Towards Data Science}, author={Howell, Egor}, year={2023}, month={Oct}} 

@misc{CURAND,
    author = {NVIDIA},
    title = {CUDA cuRAND Library Programming Guide v12.4},
    year = {2024},
    url = {https://docs.nvidia.com/cuda/curand/index.html}
}

@misc{CUFFT,
    author = {NVIDIA},
    title = {cuFFT API Reference v12.4},
    year = {2024},
    url = {https://docs.nvidia.com/cuda/cufft/index.html}
}

@ARTICLE{755612,

  author={Grama, A. and Kumar, V.},

  journal={IEEE Transactions on Knowledge and Data Engineering}, 

  title={State of the art in parallel search techniques for discrete optimization problems}, 

  year={1999},

  volume={11},

  number={1},

  pages={28-35},

  keywords={Design optimization;Parallel processing;Very large scale integration;Transportation;Processor scheduling;State-space methods;Concurrent computing;Search methods;Large-scale systems;Workstations},

  doi={10.1109/69.755612}}
